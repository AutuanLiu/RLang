---
title: "MSwM包的研究笔记"
output: html_notebook
date: "2017/07/11"
author: "autuanliu"
---
回归分析是统计学的的核心  

回归：用一个或者多个预测变量（自变量或解释变量）来预测响应变量（因变量，效标变量或结果变量）的方法

回归分析可以用来挑选与响应变量相关的解释变量，可以描述两者之间的关系，也可以生成一个等式，通过解释变量来预测响应变量

相对重要的问题：模型的所有预测变量中，哪个最重要，哪个第二重要，哪个最无关紧要

R 中做回归分析的函数已经超过205个

## 回归分析的多种形式
回归类型 | 用途
--- | --- 
简单线性 | 用一个量化的解释变量预测一个量化的响应变量 
多项式 | 用一个量化的解释变量预测一个量化的响应变量，多项式型
多层 | 用拥有层级关系的数据预测一个响应变量
多元线性 | 用多个量化的解释变量预测一个量化的响应变量
多变量 | 用一个或多个的解释变量预测一个量化的响应变量 
Logistic | 预测一个类别型响应变量
泊松 | 预测代表频数的响应变量
Cox比例风险 | 预测一个事件（死亡，失败，旧病复发）发生的时间
时间序列 | 对误差项相关的时间序列建模
非线性 | 用一个量化或多个的解释变量预测一个量化的响应变量
非参数 | 模型的形式源自于数据形式，不事先设定
稳健 | 用一个或多个量化的解释变量预测一个量化的响应变量，能抵御干扰

## 普通最小二乘回归法 OLS
OLS回归是通过预测变量的加权和来预测量化的因变量，其中权重是通过数据估计而得的参数
## 用`lm()`来拟合回归模型
`y～x1+x2+...

* 符号说明
符号 | 用途
--- | ---
～ | 分隔符，左边为响应变量，右边为解释变量
+ | 分割预测变量
： | 表示预测变量的交互项（交叉乘积）y~x+z+x:z
* |  表示所有可能交互项 y~x*z*w=y~x+z+w+x:z+x:w+z:w+x:z:w
^ | 表示交互项达到某个次数y~(x+z+w)^2=y~x+z+w+x:z+x:w+z:w
. | 表示除因变量外的所有变量，y~.=y~x+z+w
- | 表示从等式中移除某个项
-1 | 删除截距项
I() | 从算数的角度来解释，y~x+I((z+w)^2)=y~x+h,h是z和w的平方和
function | 可以在表达式中使用函数 ，log(y)~x+z+w

* 其他函数
函数 | 作用
--- | ---
summary() |
coefficients() | 列出模型参数，截距和斜率
confint() | 提供模型参数的置信区间
fitted() | 列出拟合模型的预测值
residuals() | 列出模型的残差值
anova() | 生成模型的方差分析表
vcov() | 列出模型的协方差矩阵
AIC() | 
plot() | 生成评价拟合模型的诊断图
predict() | 预测响应变量

## 简单线性回归
```{r}
data("women")
fit <- lm(weight~height, data = women)
summary(fit)
fitted(fit) # 预测值
residuals(fit) # 残差值
plot(women$height, women$weight, xlab = "Height", ylab = "Weight")
abline(fit) # 在图形上增加拟合曲线
# Weight = -87.52 + 3.45 * Height
# Pr(>|t|) 表示回归系数是否显著为 0 
```
## 多项式回归
```{r}
fit2 <- lm(weight ~ height + I(height^2), data = women[-c(13, 15)])
summary(fit2)
plot(women$height, women$weight, xlab = "Height", ylab = "Weight")
par(mfrow = c(2, 2))
plot(fit2) # 在图形上增加拟合曲线
```
#### 二元关系图
```{r}
library(car)
scatterplot(weight~height, data = women, spread = FALSE, smoother.args = list(lty = 2), pch = 19)
```
## 多元线性回归
```{r}
states <- as.data.frame(state.x77[, c("Murder", "Population", "Illiteracy", "Income", "Frost")])
# 检查相关性 cor
cor(states)
library(car)
scatterplotMatrix(states, spread = FALSE, smoother.args = list(lty = 2), main = "Scatter plot matrix")
```


```{r}
# fit line
fit4 <- lm(Murder ~ Population + Illiteracy + Income + Frost, data = states)
summary(fit4)
par(mfrow = c(2, 2))
plot(fit4)
library(car) # import package car
# qqplot(fit4, labels = row.names(states), id.method = "identify", simulate = TRUE, main = "Q-Q plot")
```

## 含交叉项的回归
```{r}
fit <- lm(mpg ~ hp + wt + hp:wt, data = mtcars)
summary(fit)
# 图形演示交叉项的影响
library(effects)
plot(effect("hp:wt", fit, , list(wt = c(2.2, 3.2, 4.2))), multiline = TRUE)
confint(fit) # confidence interval
```
## 回归诊断
```{r}
fit3 <- lm(weight ~ height, data = women[-c(13, 15)]) # remove point 13, 15
par(mfrow = c(2, 2))
plot(fit)
```
* 解释
    * 若满足正态性，则QQ图应该成45°角的直线上
    * 若因变量与自变量是线性关系则残差与预测值就没有任何的关联
    * 若满足同方差，则位置尺度图应该满足**水平线周围的点应该随机分布**
    * 残差与杠杆图：单个观测点的信息
        * 离群点： 预测效果不佳
        * 高杠杆值： 异常的预测变量值
        * 強影响点 ： 对模型参数的估计影响过大

**car 包提供了更多的回归诊断方法**
## t 检验
对两个组进行比较：**接受某种新药物治疗的患者是否较使用某种现有药物的患者表现出更大程度的改善？*
### 独立样本的 t 检验
`t.test(y~x, data)`

# y 是数值变量， x是一个二分变量

`t.test(y1, y2)`

# y1, y2 为数值变量，各组的结果变量
```R
var.equal = TRUE # 方差是否相等
alternative = “less” # 单边检验
```
e.g.
```{r}
library(MASS)
t.test(Prob~So, data = UScrime)
```
### 非独立样本的 t 检验
```{r}
sapply(UScrime[c("U1", "U2")], function(x)(c(mean = mean(x), sd = sd(x))))
with(UScrime, t.test(U1, U2, paired = TRUE))
```
### 多于两组的情况
如果可以假设数是从正态总体中分离的，那么可以使用anova函数

## 异常观测值
1. 离群点
离群点指的是预测效果不佳的点，它们通常有很大的或正或负的残差
```{r}
library(car)
outlierTest(fit)
```
2. 高杠杆值点
由许多的预测变量有关的离群点组合起来的，与响应变量值没有关系

高杠杆值可能是强影响点也可能不是，这主要看他们是否是离群点
3. 强影响点
检验强影响点：
    * cook距离或称D统计量

### 改进措施
* 删除观测点
* 变量变换
* 添加或删除变量
* 使用其他回归方法

当模型不符合正态性，线性或者同方差性假设时，一个或多个变量的变换通常可以改善或调整模型的效果，如取根式，取对数，取平方等

## 模型选择
anova函数可以比较两个嵌套模型的拟合优度
```{r}
states <- as.data.frame(state.x77[, c("Murder", "Population", "Illiteracy", "Income", "Frost")])
fit5 <- lm(Murder ~ Population + Illiteracy + Income + Frost, data = states)
fit6 <- lm(Murder ~ Population + Illiteracy, data = states)
anova(fit6, fit5)
```
* 嵌套模型

即它的一些项完全包含在另一些模型中

AIC 也可以用来比较模型，他考虑了模型的统计拟合度和用来拟合的参数数目。AIC 值较小的模型要优先选择，它说明模型使用较少的参数获得了足够的拟合度，使用 AIC() 函数实现

```{r}
AIC(fit5, fit6)
```
### 变量选择
从大量候选变量中选择最终的预测变量有：**逐步回归法**， **全子集回归**
#### 逐步回归法
模型一次添加或者删除一个变量，知道达到某个判停准则为止
MASS 包的 stepAIC() 函数可以实现逐步回归模型，依据是AIC准则
```r
stepAIC(fit, direction = "backward")
```
#### 全子集回归
所有可能的模型都会被检验

leaps包的 regsubsets()函数，通过$R^$来选择

## 交叉验证
bootstrap包的crossval()函数可以实现交叉验证
```{r}
library(bootstrap)

# function defination
shrinkage <- function(fit, k = 10) {
    require(bootstrap)
    theta.fit <- function(x, y) {
    lsfit(x, y)
  }
  
    theta.predict <- function(fit, x) {
    cbind(1, x) %*% fit$coef
  }
  
     x <- fit$model[, 2:ncol(fit$model)]
     y <- fit$model[, 1]

     result <- crossval(x, y, theta.fit, theta.predict, ngroup = k)
     r2 <- cor(y, fit$fitted.value)^2
     r2cv <- cor(y, result$cv.fit)^2
     cat("Original R-Squre = ", r2, "\n")
     cat(k, "Fold Cros-Validated R-Squre = ", r2cv, "\n")
     cat("Change = ", r2 - r2cv, "\n\n")
}

states <- as.data.frame(state.x77[, c("Murder", "Population", "Illiteracy", "Income", "Frost")])
fit <- lm(Murder ~ Population + Illiteracy + Income + Frost, data = states)
shrinkage(fit)

fit1 <- lm(Murder ~ Population + Illiteracy, data = states)
shrinkage(fit1)
}
```
shrinkage()创建了一个包含预测变量和预测值的矩阵，可以获得初始的R平方以及交叉验证的R平方
